{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "4NxT-f2D7ZCc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zJTGdNdnhcEw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn # nn contains all of Pytorch building blocks for neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "`Deep learning` is a specialised form of deep learning that involves neural network with many deep layers. Neural networks are designed to mimic the human's brain ability to recognize patterns and intercept complex data such as iamge, sound, or text\n",
        "\n",
        "### Difference b/w machine learning and deep learning\n",
        "\n",
        "<ul>\n",
        "    Machine learning is used for tabular or structured data\n",
        "  <li>\n",
        "    Machine learning requires feature engineering (select best relevant features)\n",
        "  </li>\n",
        "  <li>\n",
        "    Simpler and easy to interpret\n",
        "  </li>\n",
        "  <li>\n",
        "    Are computationally efficient and doesn't require high processing power\n",
        "  </li>\n",
        "</ul>\n",
        "\n",
        "<ul>\n",
        "    Deep learning works better for unstructured data like images, text, sound or video\n",
        "  <li>\n",
        "    Doesn't requires feature engineering\n",
        "  </li>\n",
        "  <li>\n",
        "    Due to complexity and depth, they are difficult to understand and are referred as black box\n",
        "  </li>\n",
        "  <li>\n",
        "    Works better with large amount of training data\n",
        "  </li>\n",
        "  <li>\n",
        "    Requires substantional competitive power\n",
        "  </li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "4NxT-f2D7ZCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network\n",
        "They are complex computational models that are inspired by human brain strucutre and function. It consist of following layers\n",
        "<ul>\n",
        "  <li>\n",
        "    Artifical neurons or nodes\n",
        "  </li>\n",
        "  <li>\n",
        "    Input layer\n",
        "  </li>\n",
        "  <li>\n",
        "    One or more hidden layers\n",
        "  </li>\n",
        "  <li>\n",
        "    Output layer\n",
        "  </li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "dYJC5nz2885W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Neurons` are fundamental units of neural network which\n",
        "<ul>\n",
        "  <li>\n",
        "    Recieves an input\n",
        "  </li>\n",
        "  <li>\n",
        "    Process the input\n",
        "  </li>\n",
        "  <li>\n",
        "    Produces an output\n",
        "  </li>\n",
        "</ul>\n",
        "\n",
        "Each neuron has its own linear regresion model that is used to predict output using weighted inputs"
      ],
      "metadata": {
        "id": "3soltL829amO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each neuron has an activation function that introduces non-linear into the network, enabling it to learn and model complex problems. An `activation function` decides whether a neuron should be activated or not. This means that `it will decide whether the neuron's input to the network is important or not in the process of prediction using simpler mathematical operations.`\n",
        "<ul>\n",
        "  <li>\n",
        "    Sigmoid (outputs between 0 and 1)\n",
        "  </li>\n",
        "  <li>\n",
        "    Tanh (output between -1 and 1)\n",
        "  </li>\n",
        "  <li>\n",
        "    ReLu (ouput input directly if posiive otherwise 0. Widely used in hidden layers)\n",
        "  </li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "tFARQTIQ_Vom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neurons are organized into layers. There are three main\n",
        "<ul>\n",
        "  <li>\n",
        "    Input Layer\n",
        "  </li>\n",
        "  <li>\n",
        "    Hidden layers\n",
        "  </li>\n",
        "  <li>\n",
        "    Output layer\n",
        "  </li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "eFvmGpSt9mph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Input layer` recieves an input in raw form. Each neuron in this layer represents a feature of input data\n",
        "<br/>\n",
        "`Hidden layer` are layers that transform the input into something the output layer can use\n",
        "<br/>\n",
        "`Output layer` is final layer that produces the output. The number of neurons in this layer depends on nature of task"
      ],
      "metadata": {
        "id": "1SITAX6t9_bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How neural network works?\n",
        "<ol>\n",
        "  <li>\n",
        "    Each node has its own linear regression model composed of\n",
        "      <ul>\n",
        "        <li>\n",
        "          Input Layer\n",
        "        </li>\n",
        "        <li>\n",
        "          Weight\n",
        "        </li>\n",
        "        <li>\n",
        "          Bias (Each neuron has bias that allows the activation function to be shifted left or right, which helps the model fit the data better)\n",
        "        </li>\n",
        "      </ul>\n",
        "  </li>\n",
        "  <li>\n",
        "    Once input layer is determined, weights are assigned. It helps deremine the importance of any given variable, with larger ones contributong more significantly to the output\n",
        "  </li>\n",
        "  <li>\n",
        "    All input multiplied by their respective weights are then summed\n",
        "  </li>\n",
        "  <li>\n",
        "    The sum output is passed through an activation function which determines the output\n",
        "  </li>\n",
        "  <li>\n",
        "    Output of one node becomes input of next node. This process of passing data from one layer to next layer defines the neural network as feed forward neural network\n",
        "  </li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "BmMKZpuK_sPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch\n"
      ],
      "metadata": {
        "id": "m7_sUQtB0w0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor\n",
        "`Tensors` are fundamental concept in deep learning serving as a primary data structure for storing and manipulating data. It is a multi-dimensional array that generalizes scalars, vectors, and matrices to higher dimensions"
      ],
      "metadata": {
        "id": "Xxj-LAda0-eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a way to represenst complex data structures and are essential for performing mathematical operaiton in deep learning. In Pytorchm, almost everything is referred as tensor"
      ],
      "metadata": {
        "id": "SLDObT4x1VI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In context of deep learning, tensors refers to the generalization of vectors and matrices to an arbitary number of dimensions. Another name for the same concept is *`multi-dimensional array`*"
      ],
      "metadata": {
        "id": "pJ3_4G3pH9oC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of tensors include\n",
        "\n",
        "\n",
        "*   Scalar\n",
        "*   Vector\n",
        "*   Matrix\n",
        "*   3D Tensor\n",
        "*   ND Tensor\n",
        "\n"
      ],
      "metadata": {
        "id": "5-W0m82t1l5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Scalar tensor`** are single numbers and also known as 0 dimensional tensor"
      ],
      "metadata": {
        "id": "VA3H52LK18L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(7) #scalar tensor\n",
        "print(f\"Scalar: {scalar}\")\n",
        "print(f\"Dimension of scalar: {scalar.ndim}\")\n",
        "print(f\"Type: {type(scalar)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCPk7PTAt9Ys",
        "outputId": "f2cfec84-8886-47df-a645-db9cbfd40e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar: 7\n",
            "Dimension of scalar: 0\n",
            "Type: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can retrieve the data inside a tensor as a python integer"
      ],
      "metadata": {
        "id": "d5GBc1fN2T_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Item inside the scalar: {scalar.item()}\") # Here we get the value stored as a python integer\n",
        "print(f\"Type of item stored in the scalar: {type(scalar.item())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKLcDVlWuvi2",
        "outputId": "4193c1e5-cc3d-4772-a233-fcd6c83eaa03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item inside the scalar: 7\n",
            "Type of item stored in the scalar: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Vector`** are one dimensional array of numbers"
      ],
      "metadata": {
        "id": "ZImdCIz32p7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([7, 7]) #vector has magnitude and a direction\n",
        "print(f\"Vector: {vector}\")  # you can calculate the number of dimension by counting the square\n",
        "                            # brackets []\n",
        "print(f\"Dimension of vector: {vector.ndim}\")\n",
        "print(f\"Shape of vector: {vector.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP_Hbwf8u_NJ",
        "outputId": "e148fb38-b326-4dbf-de90-c043033395ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector: tensor([7, 7])\n",
            "Dimension of vector: 1\n",
            "Shape of vector: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Matrix`** are two-dimensional array of numbers"
      ],
      "metadata": {
        "id": "1QcgNFss3JGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]]) #matrix is usally indicated with capital name\n",
        "\n",
        "print(f\"Matrix: {MATRIX}\")\n",
        "print(f\"Dimension of matrix: {MATRIX.ndim}\")\n",
        "print(f\"Shape of matrix: {MATRIX.shape}\")\n",
        "print(f\"Type of matrix: {type(MATRIX)}\")\n",
        "print(f\"First item in the matrix: {MATRIX[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQF2dXNpvhcZ",
        "outputId": "48068687-822b-4070-b16b-533266e8da3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix: tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "Dimension of matrix: 2\n",
            "Shape of matrix: torch.Size([2, 2])\n",
            "Type of matrix: <class 'torch.Tensor'>\n",
            "First item in the matrix: tensor([7, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3D Tensor** is a three-dimensional array of numbers, often used to\n",
        "represent a sequence of matrices"
      ],
      "metadata": {
        "id": "wDhal1ofJVcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " TENSOR = torch.tensor([[[1, 2],\n",
        "                         [3, 4],\n",
        "                         [4, 5]]]) # tensor are also named capital\n",
        "print(f\"Tensor: {TENSOR}\")\n",
        "print(f\"Shape of tensor: {TENSOR.shape}\")\n",
        "print(f\"Dimension of tensor: {TENSOR.ndim}\")\n",
        "print(f\"Type of tensor: {type(TENSOR)}\")\n",
        "print(f\"Second item in the tensor: {TENSOR[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N2iZnTiv6gW",
        "outputId": "74a9be9e-36e0-4f54-c3cb-28625c9f22ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[[1, 2],\n",
            "         [3, 4],\n",
            "         [4, 5]]])\n",
            "Shape of tensor: torch.Size([1, 3, 2])\n",
            "Dimension of tensor: 3\n",
            "Type of tensor: <class 'torch.Tensor'>\n",
            "Second item in the tensor: tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random tensors** are tensors filled with random values. Random numbers are crucial in deep learning for various reasons\n",
        "\n",
        "*   Weights in neural network are typically initialized with random values\n",
        "*   Random tensors can be used to introduce randomness and variability in the input data during training\n",
        "*   The way neural network learn is they start with tensors full of random numbers and then adjust those random number to better represent the data\n",
        "\n"
      ],
      "metadata": {
        "id": "dyrgF0dzJ-N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`***"
      ],
      "metadata": {
        "id": "ZmJil6GX4pry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(f\"Tensor with random values and of shape (3, 4): \\n\\n{random_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRtzz5GI4o3z",
        "outputId": "8ffa981a-2c74-43d7-889e-7c0b77e9cb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with random values and of shape (3, 4): \n",
            "\n",
            "tensor([[0.6672, 0.1332, 0.8477, 0.5400],\n",
            "        [0.7751, 0.2600, 0.5883, 0.7640],\n",
            "        [0.3466, 0.2019, 0.6494, 0.5128]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) #height, width, of color\n",
        "                                                          # channels (R, G, B)\n",
        "random_image_size_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEW9GB3xQzW8",
        "outputId": "d33ecb3b-cc0e-4bcb-af8c-08f07b5ac0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7789, 0.9671, 0.9627],\n",
              "         [0.9973, 0.0995, 0.5866],\n",
              "         [0.9299, 0.4142, 0.7746],\n",
              "         ...,\n",
              "         [0.7212, 0.3567, 0.0506],\n",
              "         [0.4683, 0.7544, 0.8661],\n",
              "         [0.9962, 0.1573, 0.9356]],\n",
              "\n",
              "        [[0.1309, 0.3091, 0.3121],\n",
              "         [0.1000, 0.6089, 0.5859],\n",
              "         [0.3567, 0.7816, 0.6649],\n",
              "         ...,\n",
              "         [0.1116, 0.6984, 0.6725],\n",
              "         [0.1077, 0.0357, 0.9666],\n",
              "         [0.9041, 0.2112, 0.4902]],\n",
              "\n",
              "        [[0.7164, 0.5593, 0.4399],\n",
              "         [0.1770, 0.1366, 0.8591],\n",
              "         [0.4599, 0.4374, 0.6637],\n",
              "         ...,\n",
              "         [0.3293, 0.8928, 0.1439],\n",
              "         [0.6255, 0.5210, 0.1135],\n",
              "         [0.3691, 0.4658, 0.5474]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.8911, 0.5221, 0.6324],\n",
              "         [0.1247, 0.4185, 0.0520],\n",
              "         [0.5082, 0.2870, 0.4402],\n",
              "         ...,\n",
              "         [0.6544, 0.6166, 0.6535],\n",
              "         [0.6125, 0.9050, 0.7228],\n",
              "         [0.4790, 0.4963, 0.1604]],\n",
              "\n",
              "        [[0.0831, 0.0322, 0.0552],\n",
              "         [0.1448, 0.1376, 0.6349],\n",
              "         [0.6246, 0.1796, 0.9551],\n",
              "         ...,\n",
              "         [0.0353, 0.7799, 0.1872],\n",
              "         [0.1659, 0.0303, 0.2253],\n",
              "         [0.3383, 0.3399, 0.7596]],\n",
              "\n",
              "        [[0.4504, 0.8244, 0.1966],\n",
              "         [0.8110, 0.2369, 0.0748],\n",
              "         [0.0506, 0.7465, 0.4360],\n",
              "         ...,\n",
              "         [0.0068, 0.3186, 0.1315],\n",
              "         [0.8027, 0.7132, 0.0545],\n",
              "         [0.0588, 0.2704, 0.2266]]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can create a tensor of zeros values\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Fnb-05Q3Rx",
        "outputId": "5f764637-45fe-4d6f-fc2a-d1c4516aee85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also create a tensor os specified shape containing only one\n",
        "ones = torch.ones(size=(4, 4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOOHc81TQ8MY",
        "outputId": "76a08064-76c4-454f-da55-98601fd23afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(0 ,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzb-N4CXREDZ",
        "outputId": "7ce664dc-25c6-4a1e-cd15-5b141772d988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_numbers = torch.arange(0, 10, 2)\n",
        "even_numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJeFsKiPRiAk",
        "outputId": "6d6eff01-10e2-4226-a355-94cff2c84a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 4, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In pytorch we use **tensor_like** function\n",
        "\n",
        "*   When you need to create new tensors that match the shape and data type of existing tensors, thus ensuring consistency\n",
        "*   Make the code more readable and concise\n",
        "*   Simplifies the process of creating tensors that share properties with an existing tensor\n",
        "\n"
      ],
      "metadata": {
        "id": "BNnuvEbMRhCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=even_numbers)\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlRzxgfORcXr",
        "outputId": "88386b48-9721-43a2-cb08-d950381a598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing tensors"
      ],
      "metadata": {
        "id": "d5M4bJSGJAhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can index tensors with the same notation just as in NumPy and other python scientific libraries"
      ],
      "metadata": {
        "id": "sZjZGGljKZsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Tensors**"
      ],
      "metadata": {
        "id": "cv48WbeLJ5kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(0, 10)\n",
        "\n",
        "print(f\"Tensor: {tensor}\")\n",
        "print(f\"\\nFirst Element: {tensor[0]}\")\n",
        "print(f\"\\nLast Element: {tensor[-1]}\")\n",
        "print(f\"\\nFirst Two elements: {tensor[:2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvTvUubVJ48a",
        "outputId": "4e70780e-a4de-443e-d0ef-12aa55c14971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "First Element: 0\n",
            "\n",
            "Last Element: 9\n",
            "\n",
            "First Two elements at 1 index: tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Tensors**"
      ],
      "metadata": {
        "id": "c-L3BtESKTb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor: {random_tensor}\")\n",
        "print(f\"\\nElement on 0 index: {random_tensor[0]}\")\n",
        "print(f\"\\nFirst Element: {random_tensor[0][0]}\")\n",
        "print(f\"\\nLast Element: {random_tensor[-1][-1]}\")\n",
        "print(f\"\\nFirst Two elements at 1 index: {random_tensor[1][:2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCVBSOM8JAz7",
        "outputId": "7a7e7771-9941-4e07-9ab2-c2cc6b395e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[0.6672, 0.1332, 0.8477, 0.5400],\n",
            "        [0.7751, 0.2600, 0.5883, 0.7640],\n",
            "        [0.3466, 0.2019, 0.6494, 0.5128]])\n",
            "\n",
            "Element on 0 index: tensor([0.6672, 0.1332, 0.8477, 0.5400])\n",
            "\n",
            "First Element: 0.6672316193580627\n",
            "\n",
            "Last Element: 0.5127742886543274\n",
            "\n",
            "First Two elements at 1 index: tensor([0.7751, 0.2600])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named tensors\n",
        "***Named tensors*** are feature in PyToch that allows you to associate names with the dimensions of a tenor, making tensor opeartion more readable and less error prone. It also improves readability and makes debugging easy"
      ],
      "metadata": {
        "id": "q12rF66yM002"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(2, 3, 3, names=('Red', 'Green', 'Blue'))\n",
        "print(f\"Tensor: {tensor}\")\n",
        "print(f\"\\nTensor name: {tensor.names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mYBoZAmM0bT",
        "outputId": "275c42ca-028a-4b7b-8e20-c0e7a00317b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[[0.0272, 0.3874, 0.4744],\n",
            "         [0.2397, 0.3241, 0.3169],\n",
            "         [0.1423, 0.6742, 0.4621]],\n",
            "\n",
            "        [[0.5829, 0.1077, 0.1516],\n",
            "         [0.8369, 0.1507, 0.9246],\n",
            "         [0.4054, 0.4225, 0.5438]]], names=('Red', 'Green', 'Blue'))\n",
            "\n",
            "Tensor name: ('Red', 'Green', 'Blue')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-055b0cc3d740>:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1921.)\n",
            "  tensor = torch.rand(2, 3, 3, names=('Red', 'Green', 'Blue'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can select a specific dimension using its name"
      ],
      "metadata": {
        "id": "TPFjH1pwN-Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red_color = tensor.select(dim='Red', index=0)\n",
        "print(f\"Red color data: \\n{red_color}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkqG9Er9N94O",
        "outputId": "73ae5ec7-d2a7-4c86-a8bd-845d5cb66e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red color data: \n",
            "tensor([[0.0272, 0.3874, 0.4744],\n",
            "        [0.2397, 0.3241, 0.3169],\n",
            "        [0.1423, 0.6742, 0.4621]], names=('Green', 'Blue'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "green_color = tensor.select(dim='Green', index=0)\n",
        "print(f\"Green color data: \\n{green_color}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXuxL_7TrwRh",
        "outputId": "685a6748-b8c1-4209-df8c-0bafa71303db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Green color data: \n",
            "tensor([[0.0272, 0.3874, 0.4744],\n",
            "        [0.5829, 0.1077, 0.1516]], names=('Red', 'Blue'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blue_color = tensor.select(dim='Blue', index=0)\n",
        "print(f\"Blue color data: \\n{blue_color}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF_W11jyr9tg",
        "outputId": "482cdda2-de4d-47ac-80b1-2d9d43217aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blue color data: \n",
            "tensor([[0.0272, 0.2397, 0.1423],\n",
            "        [0.5829, 0.8369, 0.4054]], names=('Red', 'Green'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can rename existing tensors"
      ],
      "metadata": {
        "id": "oQTAWhK4OW3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_tensor = tensor.rename(Red='red_color', Green='green_color')\n",
        "print(f\"New Tensor: {new_tensor}\")\n",
        "print(f\"\\nNew names: {new_tensor.names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uuseSg2N6ZP",
        "outputId": "8b4fd17b-a22a-4b90-a76a-3a7667e78ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Tensor: tensor([[[0.2436, 0.0957, 0.1743],\n",
            "         [0.2378, 0.0855, 0.5250],\n",
            "         [0.0725, 0.0408, 0.1775]],\n",
            "\n",
            "        [[0.6060, 0.9309, 0.7031],\n",
            "         [0.0628, 0.6746, 0.0414],\n",
            "         [0.2047, 0.2586, 0.1226]]],\n",
            "       names=('red_color', 'green_color', 'Blue'))\n",
            "\n",
            "New names: ('red_color', 'green_color', 'Blue')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing some examples"
      ],
      "metadata": {
        "id": "YycxQGmhPc3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red, green, blue =  3, 64, 64\n",
        "images = torch.rand(red, green, blue, names=('red', 'green', 'blue'))\n",
        "\n",
        "print(f\"Images {images}\")\n",
        "\n",
        "red_mean = images.mean(dim='red', keepdim=True)\n",
        "green_std = images.std(dim='green', keepdim=False)\n",
        "\n",
        "print(f\"\\nRed color mean: {red_mean}\")\n",
        "print(f\"\\nGreen color mean: {green_std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4GJJDKPbvQ",
        "outputId": "e520f29e-9414-4b01-cce9-97fa73595c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images tensor([[[0.0622, 0.1264, 0.7123,  ..., 0.7022, 0.5376, 0.0841],\n",
            "         [0.6538, 0.0045, 0.6487,  ..., 0.4707, 0.3573, 0.8898],\n",
            "         [0.6224, 0.1207, 0.6166,  ..., 0.2881, 0.8859, 0.8363],\n",
            "         ...,\n",
            "         [0.3276, 0.4432, 0.6523,  ..., 0.9133, 0.2721, 0.2487],\n",
            "         [0.6604, 0.4026, 0.8583,  ..., 0.3986, 0.3913, 0.7750],\n",
            "         [0.6729, 0.9702, 0.8605,  ..., 0.7345, 0.8964, 0.1710]],\n",
            "\n",
            "        [[0.6086, 0.8549, 0.0965,  ..., 0.2895, 0.8981, 0.5714],\n",
            "         [0.5560, 0.1346, 0.1417,  ..., 0.2531, 0.9660, 0.1326],\n",
            "         [0.4762, 0.3648, 0.7717,  ..., 0.3214, 0.6674, 0.1684],\n",
            "         ...,\n",
            "         [0.7767, 0.2220, 0.1748,  ..., 0.5914, 0.1453, 0.6945],\n",
            "         [0.7204, 0.9521, 0.3169,  ..., 0.1089, 0.5585, 0.0336],\n",
            "         [0.7296, 0.8808, 0.2808,  ..., 0.1825, 0.5623, 0.1948]],\n",
            "\n",
            "        [[0.9736, 0.8402, 0.8647,  ..., 0.5777, 0.4864, 0.8276],\n",
            "         [0.6686, 0.5525, 0.2231,  ..., 0.4558, 0.5644, 0.8896],\n",
            "         [0.7455, 0.5204, 0.2836,  ..., 0.6366, 0.8354, 0.8209],\n",
            "         ...,\n",
            "         [0.0747, 0.7809, 0.1262,  ..., 0.9271, 0.6523, 0.9887],\n",
            "         [0.3315, 0.6317, 0.4005,  ..., 0.4370, 0.6355, 0.2805],\n",
            "         [0.4008, 0.1259, 0.4123,  ..., 0.6321, 0.1656, 0.9930]]],\n",
            "       names=('red', 'green', 'blue'))\n",
            "\n",
            "Red color mean: tensor([[[0.5481, 0.6072, 0.5579,  ..., 0.5231, 0.6407, 0.4944],\n",
            "         [0.6261, 0.2305, 0.3378,  ..., 0.3932, 0.6292, 0.6373],\n",
            "         [0.6147, 0.3353, 0.5573,  ..., 0.4154, 0.7962, 0.6085],\n",
            "         ...,\n",
            "         [0.3930, 0.4820, 0.3178,  ..., 0.8106, 0.3565, 0.6440],\n",
            "         [0.5708, 0.6621, 0.5252,  ..., 0.3148, 0.5284, 0.3630],\n",
            "         [0.6011, 0.6590, 0.5179,  ..., 0.5164, 0.5415, 0.4529]]],\n",
            "       names=('red', 'green', 'blue'))\n",
            "\n",
            "Green color mean: tensor([[0.2878, 0.2450, 0.2657, 0.2819, 0.2563, 0.3037, 0.2980, 0.2765, 0.3095,\n",
            "         0.2880, 0.2764, 0.2986, 0.3255, 0.2885, 0.2658, 0.2857, 0.2932, 0.2790,\n",
            "         0.2990, 0.2751, 0.2727, 0.2863, 0.3101, 0.2722, 0.2919, 0.3075, 0.2908,\n",
            "         0.3152, 0.2767, 0.2949, 0.2675, 0.2645, 0.2898, 0.3085, 0.3168, 0.2894,\n",
            "         0.2908, 0.2960, 0.2905, 0.3010, 0.2850, 0.2764, 0.2688, 0.2983, 0.2807,\n",
            "         0.2816, 0.2742, 0.3008, 0.3153, 0.2728, 0.2674, 0.2797, 0.2738, 0.2847,\n",
            "         0.2974, 0.2955, 0.2916, 0.3294, 0.2886, 0.2942, 0.2779, 0.2639, 0.3235,\n",
            "         0.2732],\n",
            "        [0.2587, 0.3324, 0.2929, 0.3005, 0.3001, 0.2527, 0.2710, 0.3033, 0.2968,\n",
            "         0.2616, 0.2954, 0.2640, 0.3119, 0.2744, 0.2521, 0.2421, 0.2926, 0.3049,\n",
            "         0.2673, 0.3094, 0.2848, 0.2965, 0.3025, 0.3076, 0.2752, 0.2975, 0.3073,\n",
            "         0.3005, 0.2893, 0.2658, 0.2959, 0.3011, 0.3049, 0.3034, 0.2754, 0.3056,\n",
            "         0.2701, 0.2783, 0.2716, 0.2734, 0.2719, 0.2925, 0.2958, 0.2834, 0.2860,\n",
            "         0.2856, 0.2574, 0.2876, 0.2794, 0.3011, 0.2620, 0.2624, 0.3087, 0.2880,\n",
            "         0.2680, 0.3016, 0.2745, 0.2943, 0.3071, 0.2905, 0.3005, 0.3074, 0.2779,\n",
            "         0.2764],\n",
            "        [0.2961, 0.2723, 0.2808, 0.2883, 0.2911, 0.2952, 0.2990, 0.2853, 0.2912,\n",
            "         0.2989, 0.2939, 0.3069, 0.2932, 0.2873, 0.2882, 0.2888, 0.2861, 0.2777,\n",
            "         0.3187, 0.2795, 0.2773, 0.3173, 0.2903, 0.2721, 0.3022, 0.2692, 0.2743,\n",
            "         0.2908, 0.2844, 0.2698, 0.3023, 0.2986, 0.2964, 0.3188, 0.2789, 0.2731,\n",
            "         0.2794, 0.2864, 0.2612, 0.2752, 0.2918, 0.3089, 0.2913, 0.2967, 0.2592,\n",
            "         0.2862, 0.3032, 0.2695, 0.2787, 0.2707, 0.2964, 0.3008, 0.2806, 0.2836,\n",
            "         0.2849, 0.3117, 0.3048, 0.2781, 0.2731, 0.3032, 0.2703, 0.2756, 0.2611,\n",
            "         0.2889]], names=('red', 'blue'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor element attributes"
      ],
      "metadata": {
        "id": "SzTgHdsrRu6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors have some important attributes like\n",
        "\n",
        "*   **tensor.dtype** (returns the data type of the tensor's elements)\n",
        "*   **tensor.device** (indicates the device on which the tensor is stored like CPU, GPU)\n",
        "*   **tensor.numel()** (returns the total number of elements in the tensor)\n",
        "*   **tensor.layout** (returns the layout of tensor)\n",
        "*   **tensor.requires_grad** (indicates whehter gradient computation is required for the tensor?)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GDLUOP3YDk_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **dtype** argument specifies the numerical data type that will be contained in the tensor. It specifies the possible value the tensor can hold and the number of bytes per value.\n",
        "<br/>\n",
        "Computation in neural network are typically executed with 32-bit floating-point precision. 64-bit does not improve accuracy in the model and will require more memory and computing time"
      ],
      "metadata": {
        "id": "EA6UpaBCnEKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float32, # data type of the tensor\n",
        "                               device=\"cpu\", # what devices is your tensor on\n",
        "                               requires_grad=False) # want pytorch to track gradients\n",
        "float_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDTIBPITCd-7",
        "outputId": "693939c9-3a0c-40dd-93e4-701a7fb67d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#always creates a copy\n",
        "float_64_tensor = float_32_tensor.type(torch.float64) #float_32_tensor is not changed\n",
        "float_64_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRXydOulD2lq",
        "outputId": "bb5fd674-2537-4e69-a511-1bac327bba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zfLhMVdGBUa",
        "outputId": "3a8276d4-4844-4bc2-990b-a84178d7b8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Arithmetics"
      ],
      "metadata": {
        "id": "aaQB3Mt8n7k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can perform arthematic operations on the tensors**"
      ],
      "metadata": {
        "id": "ePYWcyPzMhFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# manipulating tensors\n",
        "# additions, subtraction, multiplication (element-wise), division, matrix multiplication"
      ],
      "metadata": {
        "id": "gNCuynHcGhNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ten = torch.tensor([1, 2, 3])\n",
        "print(f\"Tensor: {ten}\")\n",
        "print(f\"Adding 10 to the tensor: {ten + 10}\")\n",
        "print(f\"Multiplying 25 with the tensor: {ten * 25}\")\n",
        "print(f\"Multiplying 10 with the tensor: {torch.mul(ten, 10)}\")\n",
        "print(f\"Dividing the tensor by 2: {ten/ 2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-uWF2bIhlJ",
        "outputId": "074f06b4-283e-4aa6-d338-5e719f584202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([1, 2, 3])\n",
            "Adding 10 to the tensor: tensor([11, 12, 13])\n",
            "Multiplying 25 with the tensor: tensor([25, 50, 75])\n",
            "Multiplying 10 with the tensor: tensor([10, 20, 30])\n",
            "Dividing the tensor by 2: tensor([0.5000, 1.0000, 1.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main types of multiplication in deep learning\n",
        "\n",
        "1.   Element wise multiplication\n",
        "2.   Matrix multiplication (dot product) (most common operation in deep learning)\n",
        "\n"
      ],
      "metadata": {
        "id": "RtnaPj8V2mL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjdNfDx40f2G",
        "outputId": "9513bad4-e18e-41ae-8f5e-26f45eb93c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# element wise multiplication\n",
        "print(f\"Element wise multiplication: {tensor * tensor }\")\n",
        "print(f\"Dot multiplication: {torch.dot(tensor, tensor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX5Y7t9a0mFJ",
        "outputId": "ed72cacc-bffc-472d-a889-6f4ebfe18b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element wise multiplication: tensor([1, 4, 9])\n",
            "Dot multiplication: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tensor @ tensor` **@** is other way for matrix multiplication (not a recommended approach)"
      ],
      "metadata": {
        "id": "rlMZVhvdokh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate time taken my manually calculating dot product\n",
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] + tensor[i]\n",
        "\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrWSlQKw0tyH",
        "outputId": "d94d60bc-75eb-4396-d65b-25ee36dab3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12)\n",
            "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
            "Wall time: 20.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate time taken by using built-in dot method\n",
        "%%time\n",
        "torch.dot(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCoLCmXx1tC3",
        "outputId": "2c2dc15f-29c1-4e04-df03-cb03e6494038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 441 µs, sys: 51 µs, total: 492 µs\n",
            "Wall time: 513 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThgNAMAf1w4W",
        "outputId": "6a128726-537b-4a53-9618-f77e15b3d8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 774 µs, sys: 875 µs, total: 1.65 ms\n",
            "Wall time: 1.89 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main rules that performing matrix multiplication needs to satisfy\n",
        "\n",
        "1.   The inner dimension must match\n",
        "*   (3, 2) @ (3, 2) will not work\n",
        "*   (2, 3) @ (3, 2) will work\n",
        "*   (3, 2) @ (2, 3) will work\n",
        "\n",
        "2.   The resulting matrix has the shape of the outer dimension\n",
        "*   (2, 3) @ (3, 2) will have shape (2, 2)\n",
        "*   (3, 2) @ (2, 3) will have shape (3, 3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5U8hWipQoG7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.matmul(torch.rand(3, 2), torch.rand(3, 2)) # error because inner dimension\n",
        "                                # do not match"
      ],
      "metadata": {
        "id": "_f_JNkDF2um2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.rand(2, 3), torch.rand(3, 2)) # no error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLDtH3ec3cRm",
        "outputId": "4a298378-3b53-41da-81e6-339ad229d0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2433, 1.2289],\n",
              "        [0.0890, 0.5614]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.rand(2, 3), torch.rand(3, 2)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plJfEX_E3m0V",
        "outputId": "96e5d1a6-970e-4ef3-97bf-70fcd77502e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most common errors in deep learning is shape error. To fix our tensor shape issues, we can manipulate the shape of one of our\n",
        "tensors using a transpose"
      ],
      "metadata": {
        "id": "8Ov63Lilo9au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.rand(3, 2), torch.rand(3, 2).T) # no error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pszvA0bV5czP",
        "outputId": "9530e0f9-7b3b-40a2-c626-dfc6eed9b07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0636, 0.6495, 0.4846],\n",
              "        [0.0420, 0.3916, 0.3926],\n",
              "        [0.0702, 0.6126, 0.7372]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Aggregation"
      ],
      "metadata": {
        "id": "uAEgjjU4pH2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finding min, max, mean, sum, etc**"
      ],
      "metadata": {
        "id": "BiMfJh-opK8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(0, 100)"
      ],
      "metadata": {
        "id": "KIc5B5zb8d2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTensor: {tensor}\")\n",
        "print(f\"Minimum value: {tensor.min}\")\n",
        "print(f\"Maximum value: {tensor.max}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqyILyYn8fMy",
        "outputId": "3b8e8eec-024a-40e4-ccf5-08ea56085a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
            "Minimum value: <built-in method min of Tensor object at 0x7a41fb2f6a20>\n",
            "Maximum value: <built-in method max of Tensor object at 0x7a41fb2f6a20>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mean doesn't work with int64 or long**"
      ],
      "metadata": {
        "id": "mE5DeUnapQtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean: {torch.mean(tensor.type(torch.float32))}\")\n",
        "# converting to float32\n",
        "print(f\"Median: {tensor.median()}\")\n",
        "print(f\"Sum: {torch.sum(tensor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCfl0GDs84hy",
        "outputId": "5fb94c1e-3687-49b7-9e7b-7e6d910d8835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 49.5\n",
            "Median: 49\n",
            "Sum: 4950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positional min max of tensors\n",
        "In the context of tensors, finding positional min and max involves not only determining the minimum and maximum values but also identifying the position (*indices*) where these value occur."
      ],
      "metadata": {
        "id": "mrlExlqRp92f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Position of minimum value: {tensor.argmin()}\")\n",
        "# returns the index position where the minimum value occurs\n",
        "\n",
        "print(f\"Position of maximum value: {tensor.argmax()}\")\n",
        "# returns the index position where the minimum value occurs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pN13hxC-UEA",
        "outputId": "6166646d-89dd-4818-f061-7f4b6dec5b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position of minimum value: 53\n",
            "Position of maximum value: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(8, 8)"
      ],
      "metadata": {
        "id": "02XtCg9v-huf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor: {tensor}\")\n",
        "print(f\"Position of minimum value: {tensor.argmin()}\")\n",
        "print(f\"Position of maximum value: {tensor.argmax()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1JIwBs-l2R",
        "outputId": "8391e63a-2614-4206-806c-35cce2c14579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[9.1966e-01, 2.7856e-02, 8.5210e-01, 8.5290e-01, 2.8515e-01, 4.7567e-01,\n",
            "         7.3274e-01, 9.8351e-01],\n",
            "        [1.4489e-01, 3.4806e-01, 5.9828e-02, 2.3390e-01, 5.1137e-01, 9.0029e-01,\n",
            "         4.7636e-01, 6.9137e-01],\n",
            "        [8.3104e-02, 8.3162e-01, 5.2739e-01, 3.1169e-01, 4.1097e-01, 2.3216e-02,\n",
            "         6.4255e-01, 4.5943e-01],\n",
            "        [7.4951e-02, 5.2587e-01, 2.4780e-02, 4.1653e-01, 9.3602e-01, 9.1294e-01,\n",
            "         4.1436e-02, 7.7510e-01],\n",
            "        [8.0107e-01, 7.5273e-01, 8.5156e-01, 5.7133e-01, 5.0669e-01, 6.3028e-01,\n",
            "         1.6166e-01, 5.3324e-03],\n",
            "        [7.0224e-01, 4.9582e-01, 5.5058e-01, 4.7480e-01, 5.7500e-01, 3.1480e-01,\n",
            "         9.0592e-01, 7.0695e-01],\n",
            "        [6.0275e-03, 1.5420e-01, 5.2672e-01, 4.6139e-01, 7.6842e-01, 6.2776e-04,\n",
            "         9.2860e-01, 9.4003e-01],\n",
            "        [9.0865e-01, 1.2922e-01, 4.7545e-01, 3.4608e-01, 6.1136e-01, 9.1591e-01,\n",
            "         5.7778e-01, 8.0731e-01]])\n",
            "Position of minimum value: 53\n",
            "Position of maximum value: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping, Stacking, Qqueezing and Unsqueezing Tensors"
      ],
      "metadata": {
        "id": "NhuE2rkwzxc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Reshaping** - reshapes an input tensor to a defined shape\n",
        "*   **View** -  return a view of an input tensor of certain but keep the same memory as the originial tensor\n",
        "*   **Stacking** - combine multiple tensors on top of each other\n",
        "*   **Squeeze** -  remove all `1` dimensions from a tensor\n",
        "*   **Unsqueeze** - add a `1` dimension to a target tensor\n",
        "*   **Permute** - return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "nGgnQiV7z-FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 5)\n",
        "tensor, tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdc7oZNGDhP",
        "outputId": "cf432ea8-ab51-45eb-f081-5b711b051ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3823, 0.7687, 0.2623, 0.4473, 0.1350],\n",
              "         [0.0723, 0.2757, 0.5578, 0.1750, 0.6667],\n",
              "         [0.7786, 0.0263, 0.6258, 0.8889, 0.8857]]),\n",
              " torch.Size([3, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_reshaped = tensor.reshape(1, 15)\n",
        "tensor_reshaped, tensor_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFg-J2vyGMov",
        "outputId": "55729216-c18d-4bc0-b6d4-bd3ae4428e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3823, 0.7687, 0.2623, 0.4473, 0.1350, 0.0723, 0.2757, 0.5578, 0.1750,\n",
              "          0.6667, 0.7786, 0.0263, 0.6258, 0.8889, 0.8857]]),\n",
              " torch.Size([1, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = tensor.view(3, 5) #changing z changes tensor (because a view of tensor shares\n",
        "                    # the same memory as original)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuWvgZxEGarO",
        "outputId": "8552e668-436a-408b-d1c5-b84411bc7870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1364, 0.2351, 0.1271, 0.8342, 0.5425],\n",
              "         [0.7679, 0.2764, 0.1265, 0.2041, 0.3384],\n",
              "         [0.8958, 0.1590, 0.2624, 0.5675, 0.2305]]),\n",
              " torch.Size([3, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[:, 0] = 5"
      ],
      "metadata": {
        "id": "HotnvjPpIAfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzWtAxaUIeEA",
        "outputId": "5b4b292b-2bb7-443f-e84d-28985e4a2a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.0000, 0.2351, 0.1271, 0.8342, 0.5425],\n",
              "        [5.0000, 0.2764, 0.1265, 0.2041, 0.3384],\n",
              "        [5.0000, 0.1590, 0.2624, 0.5675, 0.2305]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stacking** combines multiple tensors along a new dimension. This is useful for creating batches of data or combining ouputs from different models\n"
      ],
      "metadata": {
        "id": "f0wVNksB3aVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stacks tensors on top of each other\n",
        "x_stacked = torch.stack([tensor, tensor], dim=2)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrulzHCkIgqd",
        "outputId": "b8ecadf4-e5b6-4d11-9fd0-ce41e463ce9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[5.0000, 5.0000],\n",
              "         [0.2351, 0.2351],\n",
              "         [0.1271, 0.1271],\n",
              "         [0.8342, 0.8342],\n",
              "         [0.5425, 0.5425]],\n",
              "\n",
              "        [[5.0000, 5.0000],\n",
              "         [0.2764, 0.2764],\n",
              "         [0.1265, 0.1265],\n",
              "         [0.2041, 0.2041],\n",
              "         [0.3384, 0.3384]],\n",
              "\n",
              "        [[5.0000, 5.0000],\n",
              "         [0.1590, 0.1590],\n",
              "         [0.2624, 0.2624],\n",
              "         [0.5675, 0.5675],\n",
              "         [0.2305, 0.2305]]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Squeezing** removes dimensions of size 1 from a tensor. This is useful for removing unnecessary dimensions, especially after operations like aggregations that can add extra dimensions."
      ],
      "metadata": {
        "id": "-DZlqRlF5jn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6]]])\n",
        "print(\"Original Tensor with extra dimension:\\n\", tensor)\n",
        "print(\"Original Tensor dimension:\", tensor.ndim)\n",
        "\n",
        "# Squeeze the tensor to remove dimensions of size 1\n",
        "squeezed_tensor = tensor.squeeze()\n",
        "print(\"\\nSqueezed Tensor:\\n\", squeezed_tensor)\n",
        "print(\"Squeezed Tensor dimension:\", squeezed_tensor.ndim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqZIa7eJIvId",
        "outputId": "86f69292-a00f-4614-cee3-f60ff631f888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor with extra dimension:\n",
            " tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "Original Tensor dimension: 3\n",
            "\n",
            "Squeezed Tensor:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Squeezed Tensor dimension: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unsqueezing** adds a dimension of size 1 to a tensor. This is useful when you need to add a batch dimension or channel dimension for specific operations or model requirements."
      ],
      "metadata": {
        "id": "FDytBC1O7wbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"Original Tensor:\\n\", tensor)\n",
        "print(\"Original Tensor dimension:\", tensor.ndim)\n",
        "\n",
        "# Unsqueeze the tensor to add a new dimension at dim=0\n",
        "unsqueezed_tensor = tensor.unsqueeze(dim=0)\n",
        "print(\"Unsqueezed Tensor along dim=0:\\n\", unsqueezed_tensor)\n",
        "print(\"Unsqueezed Tensor dimension:\", unsqueezed_tensor.ndim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08pRlBKGJSrN",
        "outputId": "798bfa1a-5942-432f-95f6-08f6cba763aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Original Tensor dimension: 2\n",
            "Unsqueezed Tensor along dim=0:\n",
            " tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "Unsqueezed Tensor dimension: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "# commonly used for images\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "x_permuted = x_original.permute(2, 0, 1) # the 2nd index (3) is re-ordered to start\n",
        "\n",
        "# re-orders the shape indexes\n",
        "\n",
        "print(f\"Original shape: {x_original.shape}\")\n",
        "print(f\"Permuted shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQg9nM3HJ1Hc",
        "outputId": "1b664cab-71b7-4f7d-f0e0-2d02a2c17c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([224, 224, 3])\n",
            "Permuted shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy and pytorch\n",
        "# numpy to pytorch (torch.from_numpy(ndarray))\n",
        "# pytorch to numpy (torch.Tensor.numpy())"
      ],
      "metadata": {
        "id": "wEnia26sKsXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array) #numpy default datatype is float64\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk7dPhSLWy0E",
        "outputId": "a865e3b7-b364-4fed-da29-f3cc9db3872d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "numpy_tensor, numpy_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hsZA07RW7Fz",
        "outputId": "f6cc2711-7b43-477c-da74-7f799e2f0501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1., 1., 1., 1., 1.], dtype=float32), dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Reproduceability"
      ],
      "metadata": {
        "id": "zQGcDlqo8PCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reproduceability in PyTorch** (or any other machine learning framework) refers to the ability to consistently reproduce the same results given the same input and condition. This is cruical for debugging, verifying experiments, and comparing models"
      ],
      "metadata": {
        "id": "5ItIpTPv8bOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Achieving reproduceability ensures that the results are reliable and can be independently verified by others or by yourself at a later time"
      ],
      "metadata": {
        "id": "Q6iKD2YI8tYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_A = torch.rand(3, 4)\n",
        "random_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Random tensor A: {random_A}\")\n",
        "print(f\"Random tensor B: {random_B}\")\n",
        "print(random_A == random_B)"
      ],
      "metadata": {
        "id": "t8G4j3eXYFOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643599c1-778b-4a48-bcaa-a7a6c23fc8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor A: tensor([[0.0482, 0.7124, 0.8801, 0.6303],\n",
            "        [0.4352, 0.1096, 0.8976, 0.8997],\n",
            "        [0.2484, 0.4821, 0.9280, 0.9965]])\n",
            "Random tensor B: tensor([[0.5120, 0.8107, 0.0403, 0.4691],\n",
            "        [0.2694, 0.5730, 0.2722, 0.0104],\n",
            "        [0.5658, 0.4776, 0.8009, 0.8854]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting seeds for random number generators ensures that the pseudo-random numbers generated are the same each time.\n",
        "<br/>\n",
        "`Random number generators` in computers are not truly random but pseudo-random. The use deterministic algorithms to produces sequences of numbers that only appear to be random"
      ],
      "metadata": {
        "id": "qI_09j8s8_56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets make some random but reproduceable tensors\n",
        "\n",
        "RANDOM_SEED = 2 # const that's why capitalized\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED) #set seed for PyTorch\n",
        "random_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Random tensor C: {random_C}\")\n",
        "print(f\"Random tensor D: {random_D}\")\n",
        "print(random_C == random_D)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7mzojKxBbCp",
        "outputId": "6db09237-e44e-4146-826a-64e2200dc1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor C: tensor([[0.6147, 0.3810, 0.6371, 0.4745],\n",
            "        [0.7136, 0.6190, 0.4425, 0.0958],\n",
            "        [0.6142, 0.0573, 0.5657, 0.5332]])\n",
            "Random tensor D: tensor([[0.6147, 0.3810, 0.6371, 0.4745],\n",
            "        [0.7136, 0.6190, 0.4425, 0.0958],\n",
            "        [0.6142, 0.0573, 0.5657, 0.5332]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read**\n",
        "<br/>\n",
        "https://pytorch.org/docs/stable/notes/randomness.html\n",
        "<br/>\n",
        "https://en.wikipedia.org/wiki/Random_seed"
      ],
      "metadata": {
        "id": "2EOSTOoSCntm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting tensors and models on GPU"
      ],
      "metadata": {
        "id": "-tXyLZwD7brD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster calculation"
      ],
      "metadata": {
        "id": "QKTIf-_g7mxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor (on CPU)\n",
        "tensor = torch.tensor([1, 2, 3], device= 'cpu')\n",
        "tensor"
      ],
      "metadata": {
        "id": "fMzZYvjREpIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c233d0-5671-44a1-9320-fcbd95f2b35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3], device='cuda')\n",
        "tensor"
      ],
      "metadata": {
        "id": "WiTieEvZxsjT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "0f089fd6-2862-4ada-f629-c04f641f1917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-18ef09b9771b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Workflow"
      ],
      "metadata": {
        "id": "1erhW1g48Luk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically pytorch workflow includes\n",
        "\n",
        "1.   Get data ready\n",
        "2.   Build or pock a pre-trained model\n",
        "      *   Build a trainig loop\n",
        "      *   Pick a loss funciton optimizer\n",
        "      *   Repeat the step 2\n",
        "\n",
        "3.   Fit the model to data to make prediction\n",
        "4.   Evaluate the model\n",
        "5.   Improve through experimentation\n",
        "6.   Save and reload your trained model\n",
        "\n"
      ],
      "metadata": {
        "id": "acvAfej3-fpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.7\n",
        "bias = 0.3"
      ],
      "metadata": {
        "id": "Qyyb6zOYKo_9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)  # capital because mostly it is matrix or tensor\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ABMpu2LVHq",
        "outputId": "5650961f-97d2-49bb-ddf3-59dd255a1f10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV_UdZnVLtiq",
        "outputId": "d63a4a0c-650e-4192-e3c1-68f23e2bbb11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training data"
      ],
      "metadata": {
        "id": "TUU0094M25Y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting data into training and test set is the most important concept in machine learning.\n",
        "<br/>\n",
        "In general\n",
        "*   Training data (60-80)%\n",
        "*   Validation data (10-20 of)% (not always used)\n",
        "*   Test data (10-20)%"
      ],
      "metadata": {
        "id": "CYgtSe-W_9iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "\n",
        "X_test, y_test = X[train_split:], y[train_split:]"
      ],
      "metadata": {
        "id": "pLN0rv_yMMpa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpjp1Nx7N-L0",
        "outputId": "9123d2ee-2dbc-453b-c18f-0278131d15e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Data\n",
        "After splitting the training and testing data, it is a good practice to visualize data to see any visible patterns or outliers"
      ],
      "metadata": {
        "id": "248g_e433DxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = None):\n",
        "  \"\"\"\n",
        "  Plot training data, test data and compares predictions\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.scatter(train_data, train_labels, c='b', s=4, label='Training data')\n",
        "            # color blue and size is 4\n",
        "\n",
        "  plt.scatter(test_data, test_labels, c='g', s=4, label='Test data')\n",
        "  if predictions is not None:\n",
        "    # plot predictions if they exists\n",
        "    plt.scatter(test_data, predictions, c='r', s=4, label='Predictions')\n",
        "\n",
        "  plt.legend(prop={\"size\": 14})\n"
      ],
      "metadata": {
        "id": "d3drZ4FkODKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "aCItTUOHPn0Y",
        "outputId": "0abbdf43-3e22-4145-e7c6-868ace5ec3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Model"
      ],
      "metadata": {
        "id": "J2xO9mNW3Bv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially, lets consider using the simplest model out there, `Linear Regression Model`\n",
        "<br/>\n",
        "**y = x * weight + bias**"
      ],
      "metadata": {
        "id": "TJRZrIYZAcLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to estimate the value of *weight* abd *bias*, which are parameters in our model, based on the data we have, such that the values of **y** through the model actually measure the data we have in **x**"
      ],
      "metadata": {
        "id": "NaO9Z56mAv3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Module is the base class for all neural network modules in PyTorch. Your\n",
        "# models should subclass this\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # nn.Parameter tells PyTorch that a tensor should be considered a parameter\n",
        "    # of a module and will be automatically added to list of its parameters\n",
        "    # Parameter is typically used to define learnablke parameters in custom\n",
        "    # layers\n",
        "    self.weights = nn.Parameter(torch.randn(1,\n",
        "                                            requires_grad=True,\n",
        "                                            dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad=True,\n",
        "                                         dtype=torch.float))\n",
        "\n",
        "  # Forward method defines the computation performed at every call of the module\n",
        "  # It is where you specify the operations that happen during the forward pass of\n",
        "  # your network. It is required\n",
        "  def forward(self, x:torch.Tensor)->torch.Tensor:\n",
        "    return self.weights * x + self.bias"
      ],
      "metadata": {
        "id": "yB-FKBCw_3Pd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with random values of weight and bias, look at training data, and adjust the random values to better represent (or get\n",
        "closer to) the ideal values that better fit the actual data"
      ],
      "metadata": {
        "id": "epnFCpL4BGnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is done by\n",
        "\n",
        "1.   Gradient Descent\n",
        "2.   Backpropagation\n",
        "\n"
      ],
      "metadata": {
        "id": "f46N8GU2BXV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Learning and Loss Functions"
      ],
      "metadata": {
        "id": "8LtjzGi43ciL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loss function (or cost function) is a function that computes a single numerical value\n",
        "that the learning process will attempt to minimize."
      ],
      "metadata": {
        "id": "dc4QzXscBXq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conceptually, a loss function is a way of prioritizing which errors to fix from our\n",
        "training samples, so that our parameter updates result in adjustments to the outputs for\n",
        "the highly weighted samples instead of changes to some other samples’ output that had\n",
        "a smaller loss."
      ],
      "metadata": {
        "id": "lfIJ-3SHBUyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Backpropagation\n",
        "**Backpropagation**, short for `backward propagation of errors` is a fundamental algorithm for training neural networks. It computes the gradient of loss function function with respect to each weight by using chain rule"
      ],
      "metadata": {
        "id": "bC9WkBEe9cl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps of backpropagation involves\n",
        "\n",
        "1.   Forward Pass\n",
        "    *   The input data is passed through the network layer by layer, to compute the output (predictions)\n",
        "\n",
        "2.   Loss Calculation\n",
        "    *   Calculate the loss using the predicted output and actual target\n",
        "    *   The loss function compares the network's predictions with the actual target values to measure the prediction error\n",
        "    *   Minimizing the loss error improves the model prediction\n",
        "\n",
        "3.   Backward propagation\n",
        "    *  Compute the gradient of the loss with respect to the output layers parameters\n",
        "    *  Propagate the error backward through each layer\n",
        "\n",
        "4.   Update parameters\n",
        "    *  Update the weights and biases using gradient descent\n",
        "\n"
      ],
      "metadata": {
        "id": "E-zk3_FB97yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Descent\n",
        "**Gradient descent** is an optimization algorithm used to minimize the loss function in the machine and deep learning algorithms. Minimizing the cost funciton improves model accuracy"
      ],
      "metadata": {
        "id": "fm-aanIT9F7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network uses gradient descent to learn by following the steps\n",
        "\n",
        "1.   Randomly initializes the network weight weights and biases\n",
        "2.   Pass the input data through network to obtain output predictions\n",
        "    *  This involves calculating weighted sums and applying activation function\n",
        "\n",
        "3. We compute the loss using predicted output and the actual target values\n",
        "4. We calcualte the gradient of loss function\n",
        "    *  Gradient points in the direction of steepest decrease in loss function\n",
        "\n",
        "5. We update the network parameter using gradients calculated during backpropagation\n",
        "\n",
        "6. Repeat the steps unitl the loss converges to minimum value\n",
        "\n"
      ],
      "metadata": {
        "id": "roRqN4G-_Xb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The difference b/w gradient and backpropagation is**\n",
        "*   *Backpropagation* is used to calculate the error and figure out how each part of the neural network contributed to error\n",
        "  * Happens after the network has made a prediction and we know how wrong it was\n",
        "\n",
        "*   *Gradient descent* is an optimization technique/algorithm that updates the neural network weight to minimize the error\n",
        "  * It happens after backpropagation"
      ],
      "metadata": {
        "id": "xOddBtBkAiD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# create an instance of the mode\n",
        "\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Checkout the parameters\n",
        "print(f\"Parameters of the model: \\n {list(model_0.parameters())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNaKntDmZ5HD",
        "outputId": "564ae98b-3892-4c78-d0a5-ce919d61b363"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of the model: \n",
            " [Parameter containing:\n",
            "tensor([0.3367], requires_grad=True), Parameter containing:\n",
            "tensor([0.1288], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Parameters of the model: {model_0.state_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aVPIzcgc6Rv",
        "outputId": "2cc8d6f8-8e6f-4228-ee51-2ba88ac4034d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of the model: OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.inference_mode** is a context manager in PyTorch used to improve the performance of inference (making predictions) by disabling gradienta computation. It is especially designed for interfernce where you do not need to update the model weights"
      ],
      "metadata": {
        "id": "mnKb9LbfHSzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyyby3uDe1_R",
        "outputId": "4d20875f-feee-4245-a1c1-4189e870fab2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4049],\n",
              "        [0.4116],\n",
              "        [0.4184],\n",
              "        [0.4251],\n",
              "        [0.4318],\n",
              "        [0.4386],\n",
              "        [0.4453],\n",
              "        [0.4520],\n",
              "        [0.4588]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "0MBxBTBXe9oB",
        "outputId": "d5ff0546-bbc5-401a-d4db-850f43d2502f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.L1Loss** is a loss function in PyTorch that calculates the mean absolute error (MAE) between the predicted values and the actual target values"
      ],
      "metadata": {
        "id": "R2lP0kCIHnHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()\n",
        "loss = loss_fn(y_preds, X_test)\n",
        "print(f\"Loss: {loss}\")"
      ],
      "metadata": {
        "id": "AXXT_9mMj5ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a618a8f-5faf-4805-fb72-a58e390a887a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.46153610944747925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IlyY_oVGfiFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}